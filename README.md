# Adaptive Semantic Cache Allocation for LLM-based LMS

**Research Repository**

## Overview

This repository contains research experiments and evaluation notebooks for a project on adaptive semantic caching for LLM-powered Learning Management Systems (LMS).

The work studies how limited cache capacity should be dynamically allocated across courses with highly heterogeneous and time-varying query workloads.
